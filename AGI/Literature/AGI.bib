@Article{Goertzel2014,
  author    = {Goertzel, Ben},
  journal   = {Journal of Artificial General Intelligence},
  title     = {Artificial general intelligence: concept, state of the art, and future prospects},
  year      = {2014},
  number    = {1},
  pages     = {1},
  volume    = {5},
  abstract  = {In recent years broad community of researchers has emerged, focusing on the original ambitious
goals of the AI field – the creation and study of software or hardware systems with general
intelligence comparable to, and ultimately perhaps greater than, that of human beings. This paper
surveys this diverse community and its progress. Approaches to defining the concept of Artificial
General Intelligence (AGI) are reviewed including mathematical formalisms, engineering, and
biology inspired perspectives. The spectrum of designs for AGI systems includes systems with
symbolic, emergentist, hybrid and universalist characteristics. Metrics for general intelligence are
evaluated, with a conclusion that, although metrics for assessing the achievement of human-level
AGI may be relatively straightforward (e.g. the Turing Test, or a robot that can graduate from
elementary school or university), metrics for assessing partial progress remain more controversial
and problematic.},
  comment   = {Citations - 587 (13/10/2024)},
  publisher = {De Gruyter Poland},
  url       = {https://intapi.sciendo.com/pdf/10.2478/jagi-2014-0001},
}

@Article{Baum2017,
  author   = {Baum, Seth},
  journal  = {Global Catastrophic Risk Institute Working Paper},
  title    = {A survey of artificial general intelligence projects for ethics, risk, and policy},
  year     = {2017},
  pages    = {17--1},
  abstract = {Artificial general intelligence (AGI) is AI that can reason across a wide range of domains. While most
AI research and development (R&D) is on narrow AI, not AGI, there is some dedicated AGI R&D. If
AGI is built, its impacts could be profound. Depending on how it is designed and used, it could either
help solve the world’s problems or cause catastrophe, possibly even human extinction.
This paper presents the first-ever survey of active AGI R&D projects for ethics, risk, and policy. The
survey attempts to identify every active AGI R&D project and characterize them in terms of seven
attributes:
 The type of institution the project is based in
 Whether the project publishes open-source code
 Whether the project has military connections
 The nation(s) that the project is based in
 The project’s goals for its AGI
 The extent of the project’s engagement with AGI safety issues
 The overall size of the project
To accomplish this, the survey uses openly published information as found in scholarly publications,
project websites, popular media articles, and other websites, including 11 technical survey papers, 8
years of the Journal of Artificial General Intelligence, 7 years of AGI conference proceedings, 2 online
lists of AGI projects, keyword searches in Google web search and Google Scholar, the author’s prior
knowledge, and additional literature and webpages identified via all of the above.
The survey identifies 45 AGI R&D projects spread across 30 countries in 6 continents, many of which
are based in major corporations and academic institutions, and some of which are large and heavily
funded. Many of the projects are interconnected via common personnel, common parent organizations,
or project collaboration.
For each of the seven attributes, some major trends about AGI R&D projects are apparent:
 Most projects are in corporations or academic institutions.
 Most projects publish open-source code.
 Few projects have military connections.
 Most projects are based in the US, and almost all are in either the US or a US ally. The only
projects that exist entirely outside US and its allies are in China or Russia, and these projects all
have strong academic and/or Western ties.
 Most projects state goals oriented towards the benefit of humanity as a whole or towards
advancing the frontiers of knowledge, which the paper refers to as “humanitarian” and
“intellectualist” goals.
 Most projects are not active on AGI safety issues.
 Most projects are in the small-to-medium size range. The three largest projects are DeepMind
(a London-based project of Google), the Human Brain Project (an academic project based in
Lausanne, Switzerland), and OpenAI (a nonprofit based in San Fransisco).
Looking across multiple attributes, some additional trends are apparent:
 There is a cluster of academic projects that state goals of advancing knowledge (i.e.,
intellectualist) and are not active on safety.
2
 There is a cluster of corporate projects that state goals of benefiting humanity (i.e.,
humanitarian) and are active on safety.
 Most of the projects with military connections are US academic groups that receive military
funding, including a sub-cluster within the academic-intellectualist-not active on safety cluster.
 All six China-based projects are small, though some are at large organizations with the
resources to scale quickly.
Figure ES1 on the next page presents an overview of the data.},
  comment  = {Citations - 158 (13/10/2024)},
  url      = {https://gcrinstitute.org/papers/033_agi-survey.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}
