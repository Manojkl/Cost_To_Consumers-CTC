@Article{Fang2024,
  author   = {Fang, Xi and Xu, Weijie and Tan, Fiona Anting and Zhang, Jiani and Hu, Ziqing and Qi, Yanjun Jane and Nickleach, Scott and Socolinsky, Diego and Sengamedu, Srinivasan and Faloutsos, Christos and others},
  title    = {Large language models (LLMs) on tabular data: Prediction, generation, and understanding-a survey},
  year     = {2024},
  abstract = {Recent breakthroughs in large language modeling have facilitated rigorous exploration of their application in diverse tasks related to tabular data modeling, such as prediction, tabular data synthesis, question answering, and table understanding. Each task presents unique challenges and opportunities. However, there is currently a lack of comprehensive review that summarizes and compares the key techniques, metrics, datasets, models, and optimization approaches in this research domain. This survey aims to address this gap by consolidating recent progress in these areas, offering a thorough survey and taxonomy of the datasets, metrics, and methodologies utilized. It identifies strengths, limitations, unexplored territories, and gaps in the existing literature, while providing some insights for future research directions in this vital and rapidly evolving field. It also provides relevant code and datasets references. Through this comprehensive review, we hope to provide interested readers with pertinent references and insightful perspectives, empowering them with the necessary tools and knowledge to effectively navigate and address the prevailing challenges in the field.},
  comment  = {Citation -27},
  ranking  = {rank5},
  url      = {https://www.amazon.science/publications/large-language-models-llms-on-tabular-data-prediction-generation-and-understanding-a-survey},
}

@Misc{Dhinakaran,
  author       = {Aparna Dhinakaran},
  howpublished = {\url{https://towardsdatascience.com/boosting-tabular-data-predictions-with-large-language-models-531337f834dc}},
  note         = {[Accessed 12-10-2024]},
  title        = {{B}oosting {T}abular {D}ata {P}redictions with {L}arge {L}anguage {M}odels --- towardsdatascience.com},
  url          = {https://towardsdatascience.com/boosting-tabular-data-predictions-with-large-language-models-531337f834dc},
}

@Misc{HongWei2024,
  author   = {Hong-Wei, Wu},
  note     = {Accessed: 2024-05-30},
  title    = {Awesome-LLM-Tabular},
  year     = {2024},
  abstract = {Since the emergence of ChatGPT, Large Language Models (LLMs) have garnered significant attention, with new advancements continuously emerging. LLMs have found applications in various domains like vision, audio, and text tasks. However, tabular data remains a crucial data format in this world. Hence, this repo focuses on collecting research papers that explore the integration of LLM technology with tabular data, and aims to save you valuable time and boost research efficiency.

Awesome-LLM-Tabular is a curated list of Large Language Model applied to Tabular Data.

This project is currently under development. Feel free to ‚≠ê (STAR) and üî≠ (WATCH) it to stay updated on the latest developments.},
  orcid    = {https://orcid.org/0009-0005-8073-5297},
  url      = {https://github.com/johnnyhwu/Awesome-LLM-Tabular},
}

@Misc{Lu,
  author       = {Weizheng Lu},
  howpublished = {\url{https://github.com/godaai/llm-table-survey}},
  note         = {[Accessed 12-10-2024]},
  title        = {GitHub - llm-table-survey},
  abstract     = {Survey on Tabular LLM},
  url          = {https://github.com/godaai/llm-table-survey},
}

@InProceedings{Li2023,
  author    = {Li, Hongxin and Su, Jingran and Chen, Yuntao and Li, Qing and ZHANG, ZHAO-XIANG},
  booktitle = {Advances in {Neural} {Information} {Processing} {Systems}},
  title     = {{SheetCopilot}: {Bringing} {Software} {Productivity} to the {Next} {Level} through {Large} {Language} {Models}},
  year      = {2023},
  editor    = {Oh, A. and Neumann, T. and Globerson, A. and Saenko, K. and Hardt, M. and Levine, S.},
  pages     = {4952--4984},
  publisher = {Curran Associates, Inc.},
  volume    = {36},
  url       = {https://proceedings.neurips.cc/paper_files/paper/2023/file/0ff30c4bf31db0119a6219e0d250e037-Paper-Conference.pdf},
}

@Article{Zhang2024,
  author    = {Zhang, Weixu and Wang, Yifei and Song, Yuanfeng and Wei, Victor Junqiu and Tian, Yuxing and Qi, Yiyan and Chan, Jonathan H and Wong, Raymond Chi-Wing and Yang, Haiqin},
  journal   = {IEEE Transactions on Knowledge and Data Engineering},
  title     = {Natural Language Interfaces for Tabular Data Querying and Visualization: A Survey},
  year      = {2024},
  abstract  = {The emergence of natural language processing has revolutionized the way users interact with tabular data, enabling a shift from traditional query languages and manual plotting to more intuitive, language-based interfaces. The rise of large language models (LLMs) such as ChatGPT and its successors has further advanced this field, opening new avenues for natural language processing techniques. This survey presents a comprehensive overview of natural language interfaces for tabular data querying and visualization, which allow users to interact with data using natural language queries. We introduce the fundamental concepts and techniques underlying these interfaces with a particular emphasis on semantic parsing, the key technology facilitating the translation from natural language to SQL queries or data visualization commands. We then delve into the recent advancements in Text-to-SQL and Text-to-Vis problems from the perspectives of datasets, methodologies, metrics, and system designs. This includes a deep dive into the influence of LLMs, highlighting their strengths, limitations, and potential for future improvements. Through this survey, we aim to provide a roadmap for researchers and practitioners interested in developing and applying natural language interfaces for data interaction in the era of large language models.},
  comment   = {Citations - 6 (12/10/2024)},
  publisher = {IEEE},
  url       = {https://arxiv.org/pdf/2310.17894},
}

@InProceedings{Zhao2024,
  author    = {Zhao, Yilun and Long, Yitao and Liu, Hongjun and Kamoi, Ryo and Nan, Linyong and Chen, Lyuhao and Liu, Yixin and Tang, Xiangru and Zhang, Rui and Cohan, Arman},
  booktitle = {Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)},
  title     = {DocMath-Eval: Evaluating Math Reasoning Capabilities of LLMs in Understanding Financial Documents},
  year      = {2024},
  pages     = {16103--16120},
  abstract  = {Recent LLMs have demonstrated remarkable performance in solving exam-like math word problems. However, the degree to which these numerical reasoning skills are effective in real-world scenarios, particularly in expert domains, is still largely unexplored. This paper introduces DocMath-Eval, a comprehensive benchmark specifically designed to evaluate the numerical reasoning capabilities of LLMs in the context of understanding and analyzing financial documents containing both text and tables. We evaluate a wide spectrum of 27 LLMs, including those specialized in math, coding and finance, with Chain-of-Thought and Program-of-Thought prompting methods. We found that even the current best-performing system (ie, GPT-4) still significantly lags behind human experts in solving complex numerical reasoning problems grounded in long contexts. We believe DocMath-Eval can be used as a valuable benchmark to evaluate LLMs‚Äô capabilities to solve challenging numerical reasoning problems in expert domains.},
  comment   = {Citations - 1 (12/10/2024)},
  url       = {https://aclanthology.org/2024.acl-long.852.pdf},
}

@InProceedings{Carlini2024,
  author       = {Carlini, Nicholas and Jagielski, Matthew and Choquette-Choo, Christopher A and Paleka, Daniel and Pearce, Will and Anderson, Hyrum and Terzis, Andreas and Thomas, Kurt and Tram{\`e}r, Florian},
  booktitle    = {2024 IEEE Symposium on Security and Privacy (SP)},
  title        = {Poisoning web-scale training datasets is practical},
  year         = {2024},
  organization = {IEEE},
  pages        = {407--425},
  abstract     = {Deep learning models are often trained on distributed, web-scale datasets crawled from the internet. In this paper, we introduce two new dataset poisoning attacks that intentionally introduce malicious examples to a model‚Äôs performance. Our attacks are immediately practical and could, today, poison 10 popular datasets. Our first attack, split-view poisoning, exploits the mutable nature of internet content to ensure a dataset annotator‚Äôs initial view of the dataset differs from the view downloaded by subsequent clients. By exploiting specific invalid trust assumptions, we show how we could have poisoned 0.01% of the LAION-400M or COYO-700M datasets for just $60 USD. Our second attack, frontrunning poisoning, targets web-scale datasets that periodically snapshot crowd-sourced content‚Äîsuch as Wikipedia‚Äîwhere an attacker only needs a time-limited window to inject malicious examples. In light of both attacks, we notify the maintainers of each affected dataset and recommended several low-overhead defenses.},
  comment      = {Citations - 139},
  url          = {https://arxiv.org/html/2302.10149v2},
}

@Article{Chalapathy2019,
  author   = {Chalapathy, Raghavendra and Chawla, Sanjay},
  journal  = {arXiv preprint arXiv:1901.03407},
  title    = {Deep learning for anomaly detection: A survey},
  year     = {2019},
  abstract = {Anomaly detection is an important problem that has been well-studied within diverse research areas
and application domains. The aim of this survey is two-fold, firstly we present a structured and comprehensive overview of research methods in deep learning-based anomaly detection. Furthermore,
we review the adoption of these methods for anomaly across various application domains and assess
their effectiveness. We have grouped state-of-the-art deep anomaly detection research techniques
into different categories based on the underlying assumptions and approach adopted. Within each
category, we outline the basic anomaly detection technique, along with its variants and present key
assumptions, to differentiate between normal and anomalous behavior. Besides, for each category,
we also present the advantages and limitations and discuss the computational complexity of the techniques in real application domains. Finally, we outline open issues in research and challenges faced
while adopting deep anomaly detection techniques for real-world problems.},
  comment  = {Citations - 2133},
  url      = {https://www.cse.fau.edu/~xqzhu/courses/cap6619/anomaly.pdf},
}

@Article{Pang2021,
  author    = {Pang, Guansong and Shen, Chunhua and Cao, Longbing and Hengel, Anton Van Den},
  journal   = {ACM computing surveys (CSUR)},
  title     = {Deep learning for anomaly detection: A review},
  year      = {2021},
  number    = {2},
  pages     = {1--38},
  volume    = {54},
  abstract  = {Anomaly detection, a.k.a. outlier detection or novelty detection, has been a lasting yet active research area in various research communities for several decades. There are still some unique problem complexities and challenges that require advanced approaches. In recent years, deep learning enabled anomaly detection, i.e., deep anomaly detection, has emerged as a critical direction. This paper surveys the research of deep anomaly detection with a comprehensive taxonomy, covering advancements in three high-level categories and 11 fine-grained categories of the methods. We review their key intuitions, objective functions, underlying assumptions, advantages and disadvantages, and discuss how they address the aforementioned challenges. We further discuss a set of possible future opportunities and new perspectives on addressing the challenges.},
  comment   = {Citations - 2237},
  publisher = {ACM New York, NY, USA},
  url       = {https://arxiv.org/pdf/2007.02500},
}

@Article{Li2024,
  author   = {Li, Aodong and Zhao, Yunhan and Qiu, Chen and Kloft, Marius and Smyth, Padhraic and Rudolph, Maja and Mandt, Stephan},
  journal  = {arXiv preprint arXiv:2406.16308},
  title    = {Anomaly detection of tabular data using llms},
  year     = {2024},
  abstract = {Large language models (LLMs) have shown their potential in long-context understanding and mathematical reasoning. In this paper, we study the problem of using LLMs to detect tabular anomalies and show that pre-trained LLMs are zeroshot batch-level anomaly detectors. That is, without extra distribution-specific model fitting, they can discover hidden outliers in a batch of data,
demonstrating their ability to identify low-density data regions. For LLMs that are not well aligned
with anomaly detection and frequently output factual errors, we apply simple yet effective datagenerating processes to simulate synthetic batchlevel anomaly detection datasets and propose an
end-to-end fine-tuning strategy to bring out the potential of LLMs in detecting real anomalies. Experiments on a large anomaly detection benchmark (ODDS) showcase i) GPT-4 has on-par
performance with the state-of-the-art transductive learning-based anomaly detection methods and ii)
the efficacy of our synthetic dataset and fine-tuning strategy in aligning LLMs to this task.},
  comment  = {Citations - 2 (13/10/2024)},
  url      = {https://arxiv.org/pdf/2406.16308},
}

@Article{Chandola2009,
  author    = {Chandola, Varun and Banerjee, Arindam and Kumar, Vipin},
  journal   = {ACM computing surveys (CSUR)},
  title     = {Anomaly detection: A survey},
  year      = {2009},
  number    = {3},
  pages     = {1--58},
  volume    = {41},
  abstract  = {Anomaly detection is an important problem that has been researched within diverse research areas
and application domains. Many anomaly detection techniques have been specifically developed
for certain application domains, while others are more generic. This survey tries to provide a
structured and comprehensive overview of the research on anomaly detection. We have grouped
existing techniques into different categories based on the underlying approach adopted by each
technique. For each category we have identified key assumptions, which are used by the techniques
to differentiate between normal and anomalous behavior. When applying a given technique to a
particular domain, these assumptions can be used as guidelines to assess the effectiveness of the
technique in that domain. For each category, we provide a basic anomaly detection technique, and
then show how the different existing techniques in that category are variants of the basic technique. This template provides an easier and succinct understanding of the techniques belonging
to each category. Further, for each category, we identify the advantages and disadvantages of the
techniques in that category. We also provide a discussion on the computational complexity of the
techniques since it is an important issue in real application domains. We hope that this survey
will provide a better understanding of the different directions in which research has been done on
this topic, and how techniques developed in one area can be applied in domains for which they
were not intended to begin with.},
  comment   = {Citations - 15083},
  publisher = {ACM New York, NY, USA},
  url       = {https://conservancy.umn.edu/server/api/core/bitstreams/108030d3-3bf3-4c58-bd60-77d0644f8359/content},
}

@InProceedings{Sukhobok2017,
  author       = {Sukhobok, Dina and Nikolov, Nikolay and Roman, Dumitru},
  booktitle    = {2017 international conference on big data innovations and applications (innovate-data)},
  title        = {Tabular data anomaly patterns},
  year         = {2017},
  organization = {IEEE},
  pages        = {25--34},
  abstract     = {One essential and challenging task in data science is data cleaning ‚Äì the process of identifying and eliminating data anomalies. Different data types, data domains, data acquisition methods, and final purposes of data cleaning have resulted in different approaches in defining data anomalies
in the literature. This paper proposes and describes a set of basic data anomalies in the form of anomaly patterns commonly encountered in tabular data, independently of the data domain, data acquisition technique, or the purpose of data cleaning. This set of anomalies can serve as a valuable basis
for developing and enhancing software products that provide general-purpose data cleaning facilities and can provide a basis for comparing different tools aimed to support tabular data cleaning capabilities. Furthermore, this paper introduces a set of corresponding data operations suitable for addressing the
identified anomaly patterns and introduces Grafterizer ‚Äì a software framework that implements those data operations.},
  comment      = {Citations - 25 (13/10/2024)},
  url          = {https://sintef.brage.unit.no/sintef-xmlui/bitstream/handle/11250/2491583/tabular-data-anomaly.pdf?sequence=1},
}

@InProceedings{Shenkar2022,
  author    = {Shenkar, Tom and Wolf, Lior},
  booktitle = {International conference on learning representations},
  title     = {Anomaly detection for tabular data with internal contrastive learning},
  year      = {2022},
  abstract  = {We consider the task of finding out-of-class samples in tabular data, where little can be assumed on the structure of the data. In order to capture the structure of the samples of the single training class, we learn mappings that maximize the mutual information between each sample and the part that is masked out. The mappings are learned by employing a contrastive loss, which considers only one sample at a time. Once learned, we can score a test sample by measuring whether the learned mappings lead to a small contrastive loss using the masked parts of this sample. Our experiments show that our method leads by a sizable accuracy gap in comparison to the literature and that the same default rule of hyperparameters
selection provides state-of-the-art results across benchmarks.},
  comment   = {Citations - 85 (13/10/2024)},
  url       = {https://openreview.net/pdf?id=_hszZbt46bT},
}

@InProceedings{Zhang2020,
  author       = {Zhang, Xuezhou and Zhu, Xiaojin and Lessard, Laurent},
  booktitle    = {Learning for Dynamics and Control},
  title        = {Online data poisoning attacks},
  year         = {2020},
  organization = {PMLR},
  pages        = {201--210},
  abstract     = {We study data poisoning attacks in the online learning setting, where training data arrive sequentially,
and the attacker is eavesdropping the data stream and has the ability to contaminate the current
data point to affect the online learning process. We formulate the optimal online attack problem
as a stochastic optimal control problem, and provide a systematic solution using tools from model
predictive control and deep reinforcement learning. We further provide theoretical analysis on the
regret suffered by the attacker for not knowing the true data sequence. Experiments validate our
control approach in generating near-optimal attacks on both supervised and unsupervised learning
tasks.},
  comment      = {Citations - 110 (13/10/2024)},
  url          = {https://proceedings.mlr.press/v120/zhang20b/zhang20b.pdf},
}

@Comment{jabref-meta: databaseType:bibtex;}
