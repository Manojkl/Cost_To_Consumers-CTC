
### Model Context Window Sizes

To do - Refer documentation and edit them

| **Model**                                          | **Context Window (Tokens)** |
|---------------------------------------------------|------------------------------|
| **Meta**                                          |                              |
| Llama 3.1-8 | 70 | 405B                          | 32,768                       |
| Llama 3-8 | 70B                               | 32,768                       |
| Llama 2-7 | 13 | 70B                           | 4,096                        |
| Llama 1-7 | 13 | 33 | 65B                      | 2,049                        |
| OPT-1.3 | 6.7 | 13 | 30 | 66B                  | 2,048                        |
| **Mistral AI**                                   |                              |
| Codestral-7 | 22B                              | 8,192                        |
| Mistral-7B                                      | 8,192                        |
| Mixtral-8x7B                                    | 8,192                        |
| Mixtral-8x22B                                   | 8,192                        |
| **Google**                                       |                              |
| Gemma2-9 | 27B                                  | 4,096                        |
| Gemma-2 | 7B                                    | 4,096                        |
| RecurrentGemma-2B                               | 4,096                        |
| **T5**                                           |                              |
| T5 (various sizes)                              | 512 (up to 4,096 for T5-11B)|
| **Apple**                                        |                              |
| OpenELM-1.1 | 3B                               | 4,096                        |
| **Microsoft**                                    |                              |
| Phi1-1.3B                                       | 2,048                        |
| Phi2-2.7B                                       | 4,096                        |
| Phi3-3.8 | 7 | 14B                             | 32,768                       |
| **AllenAI**                                      |                              |
| OLMo-7B                                         | 4,096                        |
| **xAI**                                          |                              |
| Grok-1-314B-MoE                                 | 4,096                        |
| **Cohere**                                       |                              |
| Command R-35B                                   | 8,192                        |
| **DeepSeek**                                     |                              |
| DeepSeek-Math-7B                                | 4,096                        |
| DeepSeek-Coder-1.3 | 6.7 | 7 | 33B               | 4,096                        |
| DeepSeek-VL-1.3 | 7B                             | 4,096                        |
| DeepSeek-MoE-16B                                | 8,192                        |
| DeepSeek-v2-236B-MoE                           | 32,768                       |
| DeepSeek-Coder-v2-16 | 236B-MOE                 | 32,768                       |
| **Alibaba**                                      |                              |
| Qwen-1.8B | 7B | 14B | 72B                     | 4,096                        |
| Qwen1.5-0.5B | 1.8B | 4B | 7B | 14B | 32B | 72B | 4,096  |
| Qwen2-0.5B | 1.5B | 7B | 57B-A14B-MoE | 72B | 4,096  |
| Qwen2.5-0.5B | 1.5B | 3B | 7B | 14B | 32B | 4,096  |
| CodeQwen1.5-7B                                   | 4,096                        |
| Qwen2.5-Coder-1.5B | 7B | 32B                    | 4,096                        |
| Qwen2-Math-1.5B | 7B | 72B                       | 4,096                        |
| Qwen2.5-Math-1.5B | 7B | 72B                     | 4,096                        |
| Qwen-VL-7B                                      | 4,096                        |
| Qwen2-VL-2B | 7B | 72B                          | 4,096                        |
| Qwen2-Audio-7B                                  | 4,096                        |
| **01-ai**                                        |                              |
| Yi-34B                                          | 8,192                        |
| Yi1.5-6 | 9 | 34B                               | 8,192                        |
| Yi-VL-6B | 34B                                   | 8,192                        |
| **Baichuan**                                     |                              |
| Baichuan-7 | 13B                                | 4,096                        |
| Baichuan2-7 | 13B                               | 4,096                        |
| **Nvidia**                                       |                              |
| Nemotron-4-340B                                 | 8,192                        |
| **BLOOM**                                        |                              |
| BLOOMZ&mT0                                      | 4,096                        |
| **Zhipu AI**                                     |                              |
| GLM-2 | 6 | 10 | 13 | 70B                       | 4,096                        |
| CogVLM2-19B                                     | 4,096                        |
| **OpenBMB**                                      |                              |
| MiniCPM-2B                                       | 4,096                        |
| OmniLLM-12B                                     | 8,192                        |
| VisCPM-10B                                       | 4,096                        |
| CPM-Bee-1 | 2 | 5 | 10B                         | 4,096                        |
| **RWKV Foundation**                               |                              |
| RWKV-v4 | 5 | 6                                | 4,096                        |
| **ElutherAI**                                    |                              |
| Pythia-1 | 1.4 | 2.8 | 6.9 | 12B               | 4,096                        |
| **Stability AI**                                  |                              |
| StableLM-3B                                      | 4,096                        |
| StableLM-v2-1.6 | 12B                           | 4,096                        |
| StableCode-3B                                    | 4,096                        |
| **BigCode**                                      |                              |
| StarCoder-1 | 3 | 7B                             | 4,096                        |
| StarCoder2-3 | 7 | 15B                          | 4,096                        |
| **DataBricks**                                   |                              |
| MPT-7B                                           | 4,096                        |
| DBRX-132B-MoE                                   | 4,096                        |
| **Shanghai AI Laboratory**                       |                              |
| InternLM2-1.8 | 7 | 20B                        | 4,096                        |
| InternLM-Math-7B | 20B                           | 4,096                        |
| InternLM-XComposer2-1.8 | 7B                     | 4,096                        |
| InternVL-2 | 6 | 14 | 26                        | 4,096                        |
