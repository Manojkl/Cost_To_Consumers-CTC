
1. Chain-of-Table: Evolving Tables in the Reasoning Chain for Table Understanding

Paper: https://arxiv.org/abs/2401.04398 

Task: Chain-of-Table proposes the following: given a user query over tabular data, 
plan out a sequence of tabular operations over the table to retrieve the right 
information in order to satisfy the user query. 

Abstract:
Table-based reasoning with large language models (LLMs) is a promising direction to tackle 
many table understanding tasks, such as table-based question answering and fact 
verification. Compared with generic reasoning, table-based reasoning requires the 
extraction of underlying semantics from both free-form questions and semi-structured 
tabular data. Chain-of-Thought and its similar approaches incorporate the reasoning chain 
in the form of textual context, but it is still an open question how to effectively 
leverage tabular data in the reasoning chain. We propose the Chain-of-Table framework, 
where tabular data is explicitly used in the reasoning chain as a proxy for intermediate 
thoughts. Specifically, we guide LLMs using in-context learning to iteratively generate 
operations and update the table to represent a tabular reasoning chain. LLMs can therefore 
dynamically plan the next operation based on the results of the previous ones. 
This continuous evolution of the table forms a chain, showing the reasoning process for a 
given tabular problem. The chain carries structured information of the intermediate results, 
enabling more accurate and reliable predictions. Chain-of-Table achieves new 
state-of-the-art performance on WikiTQ, FeTaQA, and TabFact benchmarks across multiple LLM 
choices.

Links:
a. https://llamahub.ai/l/llama-packs/llama-index-packs-tables?from=
b. https://github.com/run-llama/llama_index/tree/main/llama-index-packs/llama-index-packs-tables
c. https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/tables/chain_of_table/chain_of_table.ipynb 

2. Rethinking Tabular Data Understanding with Large Language Models

Paper: https://arxiv.org/abs/2312.16702 

Task: 

Proficiency of LLMs in tabular reasoning Tabular reasoning 
LLMs can reason over tabular data in 2 main ways:
- textual reasoning via direct prompting
- symbolic reasoning via program synthesis (e.g. python, SQL, etc)

Abstract:
Large Language Models (LLMs) have shown to be capable of various tasks, yet their 
capability in interpreting and reasoning over tabular data remains an underexplored area. 
In this context, this study investigates from three core perspectives: the robustness of 
LLMs to structural perturbations in tables, the comparative analysis of textual and 
symbolic reasoning on tables, and the potential of boosting model performance through the 
aggregation of multiple reasoning pathways. We discover that structural variance
of tables presenting the same content reveals a notable performance decline, particularly 
in symbolic reasoning tasks. This prompts the proposal of a method for table structure 
normalization. Moreover, textual reasoning slightly edges out symbolic reasoning, and a 
detailed error analysis reveals that each exhibits different strengths depending on the specific tasks.
Notably, the aggregation of textual and symbolic reasoning pathways, bolstered by a mix
self-consistency mechanism, resulted in achieving SOTA performance, with an accuracy of
73.6% on WIKITABLEQUESTIONS, representing a substantial advancement over previous
existing table processing paradigms of LLMs.

Links:

a. https://llamahub.ai/l/llama-packs/llama-index-packs-tables?from=
b. https://github.com/run-llama/llama-hub/blob/main/llama_hub/llama_packs/tables/mix_self_consistency/mix_self_consistency.ipynb
c. 

3. 